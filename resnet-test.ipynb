{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "\n",
    "# Custom imports\n",
    "from data import GalaxiesDataset\n",
    "from metrics import compute_accuracy, compute_confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Charger les données ***\n",
    "# Comme la classe GalaxiesDataset met toutes les données sur la mémoire vive, cette étape prend un peu de temps (1 minute sur HDD)\n",
    "# Mais ça permet ensuite de chercher des batchs très rapidement.\n",
    "dataset = GalaxiesDataset('Galaxy10_DECals.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Diviser en données d'entraînement et de test ***\n",
    "train_test_ratios = [0.8, 0.2]\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_set, test_set = random_split(dataset=dataset, lengths=train_test_ratios, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** ResNet18 avec 10 neurones sur la dernière couche ***\n",
    "class GalaxiesResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = resnet18(pretrained=pretrained, progress=False)\n",
    "        # Récupère le nombre de neurones avant la couche de classement\n",
    "        dim_before_fc = self.model.fc.in_features\n",
    "        # Change la dernière couche pleinement connecté pour avoir le bon\n",
    "        # nombre de neurones de sortie\n",
    "        self.model.fc = nn.Linear(dim_before_fc, 10)\n",
    "\n",
    "        if pretrained:\n",
    "            # Geler les paramètres qui ne font pas partie de la dernière couche fc\n",
    "            for name, param in self.model.named_parameters():\n",
    "                # Les seuls paramètres à ne pas geler sont fc.weight et fc.bias\n",
    "                if name not in [\"fc.weight\", \"fc.bias\"]:\n",
    "                    param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 1\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = GalaxiesResNet(pretrained=True)\n",
    "model.to(DEVICE)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "unfrozen_params = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "optimizer = torch.optim.SGD(params=unfrozen_params, lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Boucle d'entraînement ***\n",
    "model.train()\n",
    "\n",
    "total_batch = len(train_loader)\n",
    "\n",
    "for i_epoch in range(nb_epoch):\n",
    "\n",
    "    train_losses, start_time = [], time()\n",
    "    for i_batch, batch in enumerate(train_loader):\n",
    "        #print(\"Batch %i out of %i\"%(i_batch, total_batch))\n",
    "        images, targets = batch\n",
    "\n",
    "        images = images.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(images)\n",
    "        loss = criterion(predictions, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    print(' [-] epoch {:4}/{:}, train loss {:.6f} in {:.2f}s'.format(\n",
    "        i_epoch+1, nb_epoch, np.mean(train_losses), time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Sauvegarde modèle et poids ***\n",
    "torch.save(model.state_dict(), 'galaxies_resnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Charge modèle ***\n",
    "model = GalaxiesResNet()\n",
    "model.load_state_dict(torch.load('galaxies_resnet.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Boucle d'inférence ***\n",
    "model.eval()\n",
    "\n",
    "batch_outputs = []\n",
    "batch_targets = []\n",
    "for i_batch, batch in enumerate(test_loader):\n",
    "    images, targets = batch\n",
    "    images = images.to(DEVICE)\n",
    "    targets = targets.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "    batch_outputs.append(outputs.cpu().numpy())\n",
    "    batch_targets.append(targets.cpu().numpy())\n",
    "outputs = np.concatenate(batch_outputs, axis=0)\n",
    "predictions = outputs.argmax(axis=1)\n",
    "targets = np.concatenate(batch_targets, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Calcule l'accuracy et plot une matrice de confusion ***\n",
    "\n",
    "test_acc = compute_accuracy(targets, predictions)\n",
    "print(' [-] test acc. {:.6f}%'.format(test_acc * 100))\n",
    "\n",
    "label_dict = {\n",
    "    0: \"Disturbed\",\n",
    "    1: \"Merging\",\n",
    "    2: \"Round Smooth\",\n",
    "    3: \"In-between Round Smooth\",\n",
    "    4: \"Cigar Shaped Smooth\",\n",
    "    5: \"Barred Spiral\",\n",
    "    6: \"Unbarred Tight Spiral\",\n",
    "    7: \"Unbarred Loose Spiral\",\n",
    "    8: \"Edge-on without Bulge\",\n",
    "    9: \"Edge-on with Bulge\"\n",
    "}\n",
    "\n",
    "labels = [label_dict[i] for i in range(len(label_dict))]\n",
    "\n",
    "confusion_matrix = compute_confusion_matrix(targets, predictions, 10)\n",
    "plot_confusion_matrix(confusion_matrix, labels, \"Confusion matrix\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "6a3947e1e62811c45abef7ca4d2fbb0c7742a45e0b7a2d2a795fad37a2d5e09e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
